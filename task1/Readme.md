# Разберем установку и настройку Apache Hadoop.

## ▎Шаг 1: Настройка SSH

Перед тем как перейти к установке Hadoop, важно настроить SSH для удаленного доступа между узлами. Это необходимо для того, чтобы Hadoop мог управлять своими компонентами.

1. Установите SSH:

   На большинстве дистрибутивов Linux SSH уже установлен. Если нет, вы можете установить его с помощью следующей команды:
```bash
sudo apt update
sudo apt install openssh-server
```   

2. Создайте SSH-ключи:

   Войдите под пользователем, который будет использоваться для работы с Hadoop (например, hadoopuser):
```bash
   su - hadoopuser
   ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
```  

3. Добавьте публичный ключ в authorized_keys:

   Выполните следующую команду, чтобы добавить ваш публичный ключ в файл authorized_keys, что позволит вам подключаться к вашему узлу без пароля (также происходит и добавление внешних ключей сокомандников):
```bash
      cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```   

4. Проверьте SSH-соединение:

   Попробуйте подключиться к localhost:
```bash
      ssh localhost
```   

   Если вы сможете подключиться без запроса пароля, настройка SSH выполнена успешно.

## ▎Шаг 2: Установка Hadoop

Теперь, когда SSH настроен, мы можем перейти к установке Hadoop. 

## ▎2.1: Jump Node (Master Node)

1. В первую очередь нужно войти, а значит чтобы подключиться к jump node, нужно сделать следующее:
```bash
ssh team@ip
```
2. Необходимо обеспечить взаимодействие между всеми узлами, и для безопасности создаем специального пользователя:
```bash
sudo adduser hadoop
```
3. А дальше производим операции для нового пользователя:
   во-первых, мы входим в пользовтаеля hadoop
```bash
sudo -i -u hadoop
```
4. во-вторых, мы генерируем ключ для нашего нового пользователя:
```bash
ssh-keygen
```
5. в-третьих, мы сохраняем наш ключ на внешний носитель, а для этого выводим его на экран:
```bash
cat .ssh/id_ed25519.pub
```
Подготовительный этап завершился, поэтому непосредственно сама установка. Из-за необходимости ожидания скачивания, воспрользуемся сессионным менеджером:
```bash
tmux
```
Зайдя в котороый мы пишем команду по скачиванию дитрибутива
```bash
wget https://downloads.apache.org/hadoop/common/hadoop-3.x.x/hadoop-3.x.x.tar.gz
```
где .x.x - это версия дистрибутива на текущий день, для октября 2024 года это .4.0

И после этого выходим из сессионного менеджера.

6.Теперь надо удалить локальную адресацию, чтобы хосты знали друг друга по именам:
```bash
sudo nano /etc/hosts 
```
7.Перед нами открылся файл, в котором уже присутствуют записи, нам их нужно закомментировать, и вставляем адреса наших 4х узлов:
```bash
192.168.1.nn team-k-jn # jump node
192.168.1.nn team-k-nn # name node
192.168.1.nn team-k-dn-0 # data node
192.168.1.nn team-k-dn-1 # data node
```
Где nn - это наши хосты, а k - это номер команды (в нашем случае - это 11)

Проверяем по именам, узнала ли "машинка" как и кого зовут:
```bash
ping team-k-jn
```
```bash
ping team-k-nn
```
```bash
ping team-k-dn-0
```
```bash
ping team-k-dn-1
```
После объявления этих команд, должны быть записи с информацией по нодам, значит их имена были успешно внесены.

## ▎2.2: Name Node

После описанных выше действий переключаемся на Name Node:

```bash
ssh team-k-nn
```

Вводим пароль, потому что пока что не разложены авторизационные ключи.
И воспроизовдим эатпы под номерами 2-7 из раздела 2.1

## ▎2.3: Оставшиеся Data Node

Проделываем то же самое с как в пункте 2.2 и для двух наших data node.

## ▎2.4: После этих операций сложив все ключи мы их добавляем так чтобы можно было не вводим пароль каждый раз:

Вернуться на jump node, зайти в пользователя hadoop и сложить в файлик ключи:
```bash
nano .ssh/authorized_keys
```
Туда вписываем то, что выводили и сохраняли на каждой ноже после команды cat .ssh/id_ed25519.pub
Должно быть 4 штуки.

Теперь распространим их на все ноды.
```bash
scp .ssh/authorized_keys team-k-nn:/home/hadoop/.ssh/
scp .ssh/authorized_keys team-k-dn-0:/home/hadoop/.ssh/
scp .ssh/authorized_keys team-k-dn-1:/home/hadoop/.ssh/
```
Выше написаны три команды для каждой оставшейся ноды, после каждой нужно ввести пароль.
Теперь ноды могут взаимодействовать между собой.

## ▎2.5: Вовзаращемся к скачанному дистрибутиву

Вспоминаем, что у нас скачивался дистрибутив, и предположив, что к этому моменту он уже скачан, передаем его на все ноды.
Но перед этим выходим:
```bash
exit
```
Потом возвращаемся в сессионный менеджер для проверки того, скачалось или нет:
```bash
tmux attach -t 0
```
Ну и теперь уже передаем на ноды:
```bash
scp hadoop-3.x.x.tar.gz team-k-nn:/home/hadoop
scp hadoop-3.x.x.tar.gz team-k-dn-0:/home/hadoop
scp hadoop-3.x.x.tar.gz team-k-dn-1:/home/hadoop
```
Заходим поочередно на name node и data node и распакуем архив:
```bash
ssh team-k-nn 
tar -xvzf hadoop-3.x.x.tar.gz 
exit
```
и так же потом для data node
```bash
ssh team-k-dn-0 
tar -xvzf hadoop-3.x.x.tar.gz 
exit
```
и наконец
```bash
ssh team-k-dn-1 
tar -xvzf hadoop-3.x.x.tar.gz 
exit
```

## ▎Шаг 3: Настраиваем Hadoop

Теперь когда создана единая учетка, от имени которой будут выполняться все операции, и наконец обеспечили взаимодействие между всеми узлами: ssh-ключ и имена хостов.

А настройка начнется с name node и проверяем что версия 11.
```bash
ssh team-k-nn
java -version
```
Добалвяем переменные окружения, но для этого нужно найти местоположение:
```bash
which java # здесь у нас вышло  /usr/bin/java
readlink -f /usr/bin/java
```
Теперь открываеем файл:
```bash
nano ~/.profile
```
Добавляем переменные в файл
```bash
export HADOOP_HOME=/home/hadoop/hadoop-x.x.0 # где развернут дистрибутив
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 # где лежит java
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin # путь для выполнения исполняемых файлов hadoop
```

То же самое делаем на data nodes
```bash
scp ~/.profile team-k-dn-0:/home/hadoop
scp ~/.profile team-k-dn-1:/home/hadoop
```

