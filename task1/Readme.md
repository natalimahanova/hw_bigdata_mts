# Разберем установку и настройку Apache Hadoop.

## ▎Шаг 1: Настройка SSH

Перед тем как перейти к установке Hadoop, важно настроить SSH для удаленного доступа между узлами. Это необходимо для того, чтобы Hadoop мог управлять своими компонентами.

1. Установите SSH:

   На большинстве дистрибутивов Linux SSH уже установлен. Если нет, вы можете установить его с помощью следующей команды:
```bash
sudo apt update
sudo apt install openssh-server
```   

2. Создайте SSH-ключи:

   Войдите под пользователем, который будет использоваться для работы с Hadoop (например, hadoopuser):
```bash
   su - hadoopuser
   ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
```  

3. Добавьте публичный ключ в authorized_keys:

   Выполните следующую команду, чтобы добавить ваш публичный ключ в файл authorized_keys, что позволит вам подключаться к вашему узлу без пароля (также происходит и добавление внешних ключей сокомандников):
```bash
      cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```   

4. Проверьте SSH-соединение:

   Попробуйте подключиться к localhost:
```bash
      ssh localhost
```   

   Если вы сможете подключиться без запроса пароля, настройка SSH выполнена успешно.

## ▎Шаг 2: Установка Hadoop

Теперь, когда SSH настроен, мы можем перейти к установке Hadoop. 

## ▎2.1: Jump Node (Master Node)

1.В первую очередь нужно войти, а значит чтобы подключиться к jump node, нужно сделать следующее:
```bash
ssh team@ip
```
2.Необходимо обеспечить взаимодействие между всеми узлами, и для безопасности создаем специального пользователя:
```bash
sudo adduser hadoop
```
3.А дальше производим операции для нового пользователя:
-- во-первых, мы входим в пользовтаеля hadoop
```bash
sudo -i -u hadoop
```
4.-- во-вторых, мы генерируем ключ для нашего нового пользователя:
```bash
ssh-keygen
```
5.-- в-третьих, мы сохраняем наш ключ на внешний носитель, а для этого выводим его на экран:
```bash
cat .ssh/id_ed25519.pub
```
Подготовительный этап завершился, поэтому непосредственно сама установка. Из-за необходимости ожидания скачивания, воспрользуемся сессионным менеджером:
```bash
tmux
```
Зайдя в котороый мы пишем команду по скачиванию дитрибутива
```bash
wget https://downloads.apache.org/hadoop/common/hadoop-3.x.x/hadoop-3.x.x.tar.gz
```
где .x.x - это версия дистрибутива на текущий день, для октября 2024 года это .4.0

И после этого выходим из сессионного менеджера.

6.Теперь надо удалить локальную адресацию, чтобы хосты знали друг друга по именам:
```bash
sudo nano /etc/hosts 
```
7.Перед нами открылся файл, в котором уже присутствуют записи, нам их нужно закомментировать, и вставляем адреса наших 4х узлов:
```bash
192.168.1.nn team-k-jn # jump node
192.168.1.nn team-k-nn # name node
192.168.1.nn team-k-dn-0 # data node
192.168.1.nn team-k-dn-1 # data node
```
Где nn - это наши хосты, а k - это номер команды (в нашем случае - это 11)

Проверяем по именам, узнала ли "машинка" как и кого зовут:
```bash
ping team-k-jn
```
```bash
ping team-k-nn
```
```bash
ping team-k-dn-0
```
```bash
ping team-k-dn-1
```
После объявления этих команд, должны быть записи с информацией по нодам, значит их имена были успешно внесены.

## ▎2.2: Name Node

После описанных выше действий переключаемся на Name Node:

```bash
ssh team-k-nn
```
Вводим пароль, потому что пока что не разложены авторизационные ключи.
И воспроизовдим эатпы под номерами 2-7 из раздела 2.1

## ▎2.3: Оставшиеся Data Node

Проделываем то же самое с как в пункте 2.2 и для двух наших data node.

